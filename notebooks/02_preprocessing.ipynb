{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing \n",
    "\n",
    "In this notebook, we prepare the dataset for modeling by applying transformations such as normalization, feature creation, and data splitting. \n",
    "\n",
    "### Main steps:\n",
    "- Normalize relevant features\n",
    "- Create engineered variables\n",
    "- Split the dataset into training, validation and test sets\n",
    "- Save the processed data for reuse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.data_loader import load_raw_data, save_processed_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_raw_data()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Amount column\n",
    "\n",
    "The `Amount` feature will be standardized using `StandardScaler` to ensure it has zero mean and unit variance. This helps prevent models from being biased toward high-magnitude features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "df[\"Amount_Scaled\"] = scaler.fit_transform(df[[\"Amount\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "We will now create new variables to enrich the dataset. These features are designed to highlight behavior over time or relative to other transactions, which can help improve model performance.\n",
    "\n",
    "The following features will be added:\n",
    "- `Hour`: transaction hour (based on the `Time` feature)\n",
    "- `Amount_to_mean_ratio`: ratio between the transaction amount and the global mean\n",
    "- `Amount_to_std_ratio`: deviation from the mean amount in terms of standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Time (in seconds) to transaction hour\n",
    "df[\"Hour\"] = (df[\"Time\"] // 3600) % 24\n",
    "\n",
    "# Global statistics for amount\n",
    "mean_amount = df[\"Amount\"].mean()\n",
    "std_amount = df[\"Amount\"].std()\n",
    "\n",
    "# Create new features\n",
    "df[\"Amount_to_mean_ratio\"] = df[\"Amount\"] / mean_amount\n",
    "df[\"Amount_to_std_ratio\"] = (df[\"Amount\"] - mean_amount) / std_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount_to_mean_ratio</th>\n",
       "      <th>Amount_to_std_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.193372e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.831026</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.532288e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.063385</td>\n",
       "      <td>-3.308395e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.249011</td>\n",
       "      <td>-2.652710e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.873405</td>\n",
       "      <td>-4.471699e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>290.789708</td>\n",
       "      <td>1.023621e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Amount_to_mean_ratio  Amount_to_std_ratio\n",
       "count         284807.000000         2.848070e+05\n",
       "mean               1.000000         3.193372e-17\n",
       "std                2.831026         1.000000e+00\n",
       "min                0.000000        -3.532288e-01\n",
       "25%                0.063385        -3.308395e-01\n",
       "50%                0.249011        -2.652710e-01\n",
       "75%                0.873405        -4.471699e-02\n",
       "max              290.789708         1.023621e+02"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Amount_to_mean_ratio\", \"Amount_to_std_ratio\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting\n",
    "\n",
    "We split the dataset into three subsets:\n",
    "- **80% for training**\n",
    "- **10% for validation (dev set)**\n",
    "- **10% for testing**\n",
    "\n",
    "Given the dataset's size (284,807 transactions), allocating 10% for both validation and test sets results in ~28,480 samples for each. This is more than enough to support stable model tuning and unbiased final evaluation.\n",
    "\n",
    "Stratified sampling is used to preserve the original fraud/non-fraud ratio in all subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Class\"])\n",
    "y = df[\"Class\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=7\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=7\n",
    ")\n",
    "\n",
    "save_processed_data(pd.concat([X_train, y_train], axis=1), split=\"train\")\n",
    "save_processed_data(pd.concat([X_val, y_val], axis=1), split=\"val\")\n",
    "save_processed_data(pd.concat([X_test, y_test], axis=1), split=\"test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
